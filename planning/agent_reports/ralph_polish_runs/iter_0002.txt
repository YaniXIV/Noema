OpenAI Codex v0.98.0 (research preview)
--------
workdir: /Users/yani/Noema/backend
model: gpt-5.2-codex
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: none
reasoning summaries: auto
session id: 019c3c7b-0c2b-7e10-8559-dba3309205bb
--------
user
You are an autonomous coding agent polishing the Noema repository.

Hard rules:
- DO NOT run git commit, git reset, git clean, or anything that modifies git history.
- I will run git commits outside of you.
- Keep changes small: max 3 files per iteration.
- No cosmetic-only edits.
- No new dependencies unless absolutely necessary.

Goal: continuously improve production quality.

Iteration:
1) Run: cd backend && go test ./...
2) If failing: fix the smallest root cause (max 3 files), rerun tests until passing.
3) If passing: make ONE meaningful improvement (max 3 files), then rerun tests until passing.

Pick the highest-value improvement:
A) Reliability/correctness: validation, error handling, run persistence, verify robustness
B) Tests: add/strengthen tests for the change you made
C) Gemini integration correctness (only when eval_output missing) with deterministic fallback
D) Maintainability: reduce duplication with tiny refactors
E) UX: wizard/results/verify clarity (small, safe changes)
F) Docs: README/DEPLOYMENT polish
G) Performance: safe wins only

Finish with:
- What you changed (short)
- Tests run (must include go test ./...)
mcp startup: no servers
exec
/bin/zsh -lc 'cd /Users/yani/Noema/backend && go test ./...' in /Users/yani/Noema/backend succeeded in 94ms:
?   	noema/cmd/server	[no test files]
?   	noema/internal/auth	[no test files]
?   	noema/internal/config	[no test files]
?   	noema/internal/crypto	[no test files]
ok  	noema/internal/evaluate	(cached)
?   	noema/internal/gemini	[no test files]
?   	noema/internal/session	[no test files]
?   	noema/internal/verify	[no test files]
?   	noema/internal/web	[no test files]
ok  	noema/internal/zk	(cached)

thinking
**Preparing for targeted improvement**

I'm planning to inspect the repo with searches to identify a meaningful improvement affecting up to three files.
exec
/bin/zsh -lc 'cd /Users/yani/Noema/backend && rg -n "TODO|FIXME|panic|TODO" internal' in /Users/yani/Noema/backend exited 1 in 52ms:


thinking
**Planning validation addition**

No matches were found in the search, so I'll explore the codebase further by listing files to identify where to add validation improvements.
exec
/bin/zsh -lc 'cd /Users/yani/Noema/backend && ls' in /Users/yani/Noema/backend succeeded in 52ms:
cmd
data
go.mod
go.sum
internal
main
server
web

thinking
**Reviewing internal packages for error handling**
exec
/bin/zsh -lc 'cd /Users/yani/Noema/backend && rg -n "TODO|FIXME|panic|log.Fatal|Must" internal' in /Users/yani/Noema/backend exited 1 in 52ms:


thinking
**Checking for untested functions**

I'll look into internal/verify or evaluate modules to identify functions missing tests and target a small correctness improvement.
exec
/bin/zsh -lc 'cd /Users/yani/Noema/backend && rg -n "error" internal/verify internal/evaluate internal/session' in /Users/yani/Noema/backend succeeded in 52ms:
internal/evaluate/prompt.go:160:func marshalSampledDataset(ds Dataset) ([]byte, error) {
internal/verify/handler.go:32:			c.JSON(http.StatusBadRequest, gin.H{"error": "invalid JSON body"})
internal/verify/handler.go:36:			c.JSON(http.StatusBadRequest, gin.H{"error": "missing proof or public inputs"})
internal/verify/handler.go:52:			c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
internal/verify/handler.go:63:func verifyLegacyStub(runID, proofB64, publicInputsB64 string) (bool, string, error) {
internal/evaluate/cache.go:43:func loadCache(runsDir, key string) (*CachedGeminiOutput, error) {
internal/evaluate/cache.go:56:func saveCache(runsDir, key string, out CachedGeminiOutput) error {
internal/evaluate/parse.go:11:func parseSpec(form *multipart.Form) (Spec, error) {
internal/evaluate/parse.go:23:func validateSpec(spec Spec) error {
internal/evaluate/parse.go:40:func parseUploads(form *multipart.Form) (*multipart.FileHeader, []*multipart.FileHeader, error) {
internal/evaluate/parse.go:65:func validateDatasetJSON(fh *multipart.FileHeader) error {
internal/evaluate/policy.go:10:func enabledConstraints(spec Spec) (map[string]ConstraintRule, error) {
internal/evaluate/dataset.go:22:func readDatasetFile(fh *multipart.FileHeader) ([]byte, Dataset, error) {
internal/evaluate/output.go:22:func parseEvalOutput(raw string) (EvalOutput, error) {
internal/evaluate/output.go:49:func validateEvalOutput(out EvalOutput, enabled map[string]ConstraintRule) error {
internal/evaluate/storage.go:21:func ensureRunDir(path string) error {
internal/evaluate/storage.go:25:func saveRunFiles(runPath string, dataset *multipart.FileHeader, images []*multipart.FileHeader) error {
internal/evaluate/storage.go:42:func saveUpload(fh *multipart.FileHeader, dst string) error {
internal/evaluate/storage.go:57:func saveJSON(path string, v any) error {
internal/evaluate/storage.go:76:func updateRunsIndex(runsDir string, limit int, entry RunIndexEntry) error {

thinking
**Inspecting error handling in evaluate/handler.go**
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,240p' internal/evaluate/handler.go" in /Users/yani/Noema/backend succeeded in 52ms:
package evaluate

import (
	"encoding/json"
	"log"
	"mime/multipart"
	"net/http"
	"os"
	"path/filepath"
	"sort"
	"time"

	"noema/internal/config"
	"noema/internal/zk"

	"github.com/gin-gonic/gin"
)

// EvaluateResponse is the JSON response for POST /api/evaluate.
type EvaluateResponse struct {

thinking
**Reviewing error handling and stability**

Identified that mustJSON returns nil on errors but marshal failures are rare; considering minor improvements there. Noticed parseEvalOutputOptional uses a stub without deterministic ordering, which might be okay. Considering making pruneRuns more robust if the runs directory is missing, though it's expected to exist. Also flagged readDatasetFile's size enforcement as a possible check.
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,200p' internal/evaluate/parse.go" in /Users/yani/Noema/backend succeeded in 51ms:
package evaluate

import (
	"encoding/json"
	"fmt"
	"mime/multipart"

	"noema/internal/config"
)

func parseSpec(form *multipart.Form) (Spec, error) {
	specStrs := form.Value["spec"]
	if len(specStrs) == 0 || specStrs[0] == "" {
		return Spec{}, fmt.Errorf("missing field: spec")
	}
	var spec Spec
	if err := json.Unmarshal([]byte(specStrs[0]), &spec); err != nil {
		return Spec{}, fmt.Errorf("invalid spec JSON")
	}
	return spec, nil

thinking
**Checking output parsing in evaluation**
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,200p' internal/evaluate/output.go" in /Users/yani/Noema/backend succeeded in 52ms:
package evaluate

import (
	"bytes"
	"encoding/json"
	"fmt"
)

type EvalConstraintResult struct {
	ID        string `json:"id"`
	Severity  int    `json:"severity"`
	Rationale string `json:"rationale"`
}

type EvalOutput struct {
	SchemaVersion int                    `json:"schema_version"`
	Constraints   []EvalConstraintResult `json:"constraints"`
	MaxSeverity   int                    `json:"max_severity"`
	Confidence    *float64               `json:"confidence,omitempty"`
}

thinking
**Reviewing parse and directory error handling**

I'm checking if the eval output JSON parsing tolerates trailing whitespace and confirming that unknown fields are disallowed. Also considering if parseEvalOutputOptional's use of nil forms is appropriate. For pruneRuns, I may update handling to return nil if the runs directory is missing, though ensureRunDir likely guarantees its existence for new runs.
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,200p' internal/evaluate/storage.go" in /Users/yani/Noema/backend succeeded in 52ms:
package evaluate

import (
	"crypto/rand"
	"encoding/json"
	"fmt"
	"io"
	"math/big"
	"mime/multipart"
	"os"
	"path/filepath"
	"strconv"
	"time"
)

func genRunID() string {
	n, _ := rand.Int(rand.Reader, big.NewInt(1e9))
	return fmt.Sprintf("run_%d_%d", time.Now().UnixMilli(), n.Int64())
}


thinking
**Reviewing dataset validation**

I'm checking dataset file handling in internal/evaluate/dataset.go to assess if content size validation can improve saveRunFiles error details.
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,200p' internal/evaluate/dataset.go" in /Users/yani/Noema/backend succeeded in 51ms:
package evaluate

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"mime/multipart"
)

type Dataset struct {
	Items []DatasetItem `json:"items"`
}

type DatasetItem struct {
	ID       string         `json:"id"`
	Text     string         `json:"text"`
	Metadata map[string]any `json:"metadata,omitempty"`
	ImageRef string         `json:"image_ref,omitempty"`
}

thinking
**Considering ID uniqueness and image reference validation**

I'm planning to verify that IDs are unique and that image references correctly match provided images by reviewing the image reading logic in the internal/evaluate/images.go file to improve reliability.
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,200p' internal/evaluate/images.go" in /Users/yani/Noema/backend succeeded in 51ms:
package evaluate

import (
	"fmt"
	"io"
	"mime"
	"mime/multipart"
	"path/filepath"
	"strings"
)

type ImageInfo struct {
	Filename string
	MIMEType string
	Data     []byte
}

func readImages(files []*multipart.FileHeader) ([]ImageInfo, error) {
	out := make([]ImageInfo, 0, len(files))
	for _, fh := range files {

thinking
**Checking image reference usage**

I'll investigate how image_ref is used and whether it should be validated against the images in the dataset or spec to ensure consistency.
exec
/bin/zsh -lc 'cd /Users/yani/Noema/backend && rg -n "image_ref|ImageRef"' in /Users/yani/Noema/backend succeeded in 52ms:
internal/evaluate/prompt.go:103:		buf.WriteString("Images attached (matched by items[].image_ref to filename):\n")
internal/evaluate/dataset.go:19:	ImageRef string         `json:"image_ref,omitempty"`
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,200p' internal/evaluate/prompt.go" in /Users/yani/Noema/backend succeeded in 51ms:
package evaluate

import (
	"bytes"
	"encoding/json"
	"fmt"
	"sort"
	"strings"
)

const promptVersion = "noema-eval-v1"

type PromptConstraint struct {
	ID                 string
	Description        string
	SeverityLevels     map[string]string
	AllowedMaxSeverity int
}

var presetConstraints = map[string]PromptConstraint{

thinking
**Evaluating image reference validation**

Considering adding validation to ensure image references in the dataset match provided files, but current parsing splits dataset reading and upload parsing, complicating cross-validation; next is to review evaluation and parsing flows to find the best integration point without redundant reads.
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,200p' internal/evaluate/gemini_eval.go" in /Users/yani/Noema/backend succeeded in 52ms:
package evaluate

import (
	"context"
	"log"
	"mime/multipart"

	"noema/internal/config"
	"noema/internal/gemini"
)

func resolveEvalOutput(ctx context.Context, form *multipart.Form, enabled map[string]ConstraintRule, runsDir string, spec Spec, datasetFile *multipart.FileHeader, imageFiles []*multipart.FileHeader) (EvalOutput, error) {
	if form != nil && len(form.Value["eval_output"]) > 0 && form.Value["eval_output"][0] != "" {
		raw := form.Value["eval_output"][0]
		out, err := parseEvalOutput(raw)
		if err != nil {
			return EvalOutput{}, err
		}
		if err := validateEvalOutput(out, enabled); err != nil {
			return EvalOutput{}, err


thinking
**Planning dataset image_ref validation**

I'm restructuring parseUploads to read imageFiles before validating the dataset, then adding a new validateDatasetJSONWithImages function to check image_refs against uploaded images and error on mismatches. I'll cover this with new tests for improved reliability.
thinking
**Scoping files to update**

The plan is to update parse.go, dataset.go, and handler_test.go to implement image_ref validation; next I'll inspect handler_test.go for relevant tests.
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && sed -n '1,220p' internal/evaluate/handler_test.go" in /Users/yani/Noema/backend succeeded in 52ms:
package evaluate

import (
	"encoding/json"
	"mime/multipart"
	"sort"
	"testing"
)

func TestParseEvalOutputOptional_DefaultsToStub(t *testing.T) {
	spec := Spec{
		SchemaVersion: 1,
		Constraints: []Constraint{
			{ID: "pii_exposure_risk", Enabled: true, AllowedMaxSeverity: 1},
			{ID: "harm_enabling_content_risk", Enabled: true, AllowedMaxSeverity: 2},
		},
	}
	enabled, err := enabledConstraints(spec)
	if err != nil {
		t.Fatalf("enabledConstraints error: %v", err)


thinking
**Designing dataset validation with images**

Considering adding a new helper to validate dataset image references alongside dataset JSON, likely in dataset.go without causing import cycles. Planning to call this from parseUploads after parsing image files, keeping readDatasetFile unchanged to avoid overloading its responsibilities.
thinking
**Detailing validation logic and test approach**

I've outlined a clear validateDatasetJSON implementation that cross-checks dataset image references with uploaded images, handling missing or unmatched files with errors. Planning to move this helper to dataset.go and adjust parseUploads to validate after extracting imageFiles, while also preparing to add targeted tests simulating multipart file uploads.
exec
/bin/zsh -lc "cd /Users/yani/Noema/backend && rg -n \"multipart.FileHeader\" internal/evaluate -g '*test.go'" in /Users/yani/Noema/backend exited 1 in 52ms:



thinking
**Planning multipart.FileHeader test helper**

I'm planning to create a helper that builds an in-memory multipart form with files using multipart.Writer and then parses it with multipart.Reader to get FileHeader instances for testing file uploads. This avoids manually instantiating FileHeader, which is tricky due to unexported fields.
thinking
**Designing multipart form helper and validation tests**

I'm defining a buildMultipartForm helper that creates multipart forms with custom content types using CreatePart, returning parsed multipart.Form for tests. I'll add minimal tests for dataset-image reference validation covering missing and mismatched images, cleaning up with form.RemoveAll after tests.
file update
M /Users/yani/Noema/backend/internal/evaluate/parse.go
@@ -48,6 +48,2 @@
 	}
-	if err := validateDatasetJSON(datasetFile); err != nil {
-		return nil, nil, err
-	}
-
 	imageFiles := form.File["images"]
@@ -61,2 +57,5 @@
 	}
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		return nil, nil, err
+	}
 	return datasetFile, imageFiles, nil
@@ -64,5 +63,28 @@
 
-func validateDatasetJSON(fh *multipart.FileHeader) error {
-	_, _, err := readDatasetFile(fh)
-	return err
+func validateDatasetJSON(fh *multipart.FileHeader, imageFiles []*multipart.FileHeader) error {
+	_, ds, err := readDatasetFile(fh)
+	if err != nil {
+		return err
+	}
+	if len(imageFiles) == 0 {
+		for i, item := range ds.Items {
+			if item.ImageRef != "" {
+				return fmt.Errorf("dataset.items[%d].image_ref provided but no images uploaded", i)
+			}
+		}
+		return nil
+	}
+	imageNames := make(map[string]struct{}, len(imageFiles))
+	for _, img := range imageFiles {
+		imageNames[img.Filename] = struct{}{}
+	}
+	for i, item := range ds.Items {
+		if item.ImageRef == "" {
+			continue
+		}
+		if _, ok := imageNames[item.ImageRef]; !ok {
+			return fmt.Errorf("dataset.items[%d].image_ref must match an uploaded filename", i)
+		}
+	}
+	return nil
 }
apply_patch(auto_approved=true) exited 0 in 28ms:
Success. Updated the following files:
M /Users/yani/Noema/backend/internal/evaluate/parse.go
file update:
diff --git a/backend/internal/evaluate/parse.go b/backend/internal/evaluate/parse.go
index 52f3936303d07fdb5fb866257779af77cb860f81..5fc2e874e76c17e562acdc5bd1a08ade0d900cf6
--- a/backend/internal/evaluate/parse.go
+++ b/backend/internal/evaluate/parse.go
@@ -46,10 +46,6 @@
 	if datasetFile.Size > config.MaxDatasetBytes {
 		return nil, nil, fmt.Errorf("dataset exceeds 50MB limit")
 	}
-	if err := validateDatasetJSON(datasetFile); err != nil {
-		return nil, nil, err
-	}
-
 	imageFiles := form.File["images"]
 	if len(imageFiles) > config.MaxImages {
 		return nil, nil, fmt.Errorf("maximum 10 images allowed")
@@ -59,10 +55,36 @@
 			return nil, nil, fmt.Errorf("each image must be at most 5MB")
 		}
 	}
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		return nil, nil, err
+	}
 	return datasetFile, imageFiles, nil
 }
 
-func validateDatasetJSON(fh *multipart.FileHeader) error {
-	_, _, err := readDatasetFile(fh)
-	return err
+func validateDatasetJSON(fh *multipart.FileHeader, imageFiles []*multipart.FileHeader) error {
+	_, ds, err := readDatasetFile(fh)
+	if err != nil {
+		return err
+	}
+	if len(imageFiles) == 0 {
+		for i, item := range ds.Items {
+			if item.ImageRef != "" {
+				return fmt.Errorf("dataset.items[%d].image_ref provided but no images uploaded", i)
+			}
+		}
+		return nil
+	}
+	imageNames := make(map[string]struct{}, len(imageFiles))
+	for _, img := range imageFiles {
+		imageNames[img.Filename] = struct{}{}
+	}
+	for i, item := range ds.Items {
+		if item.ImageRef == "" {
+			continue
+		}
+		if _, ok := imageNames[item.ImageRef]; !ok {
+			return fmt.Errorf("dataset.items[%d].image_ref must match an uploaded filename", i)
+		}
+	}
+	return nil
 }

file update:
diff --git a/backend/internal/evaluate/parse.go b/backend/internal/evaluate/parse.go
index 52f3936303d07fdb5fb866257779af77cb860f81..5fc2e874e76c17e562acdc5bd1a08ade0d900cf6
--- a/backend/internal/evaluate/parse.go
+++ b/backend/internal/evaluate/parse.go
@@ -46,10 +46,6 @@
 	if datasetFile.Size > config.MaxDatasetBytes {
 		return nil, nil, fmt.Errorf("dataset exceeds 50MB limit")
 	}
-	if err := validateDatasetJSON(datasetFile); err != nil {
-		return nil, nil, err
-	}
-
 	imageFiles := form.File["images"]
 	if len(imageFiles) > config.MaxImages {
 		return nil, nil, fmt.Errorf("maximum 10 images allowed")
@@ -59,10 +55,36 @@
 			return nil, nil, fmt.Errorf("each image must be at most 5MB")
 		}
 	}
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		return nil, nil, err
+	}
 	return datasetFile, imageFiles, nil
 }
 
-func validateDatasetJSON(fh *multipart.FileHeader) error {
-	_, _, err := readDatasetFile(fh)
-	return err
+func validateDatasetJSON(fh *multipart.FileHeader, imageFiles []*multipart.FileHeader) error {
+	_, ds, err := readDatasetFile(fh)
+	if err != nil {
+		return err
+	}
+	if len(imageFiles) == 0 {
+		for i, item := range ds.Items {
+			if item.ImageRef != "" {
+				return fmt.Errorf("dataset.items[%d].image_ref provided but no images uploaded", i)
+			}
+		}
+		return nil
+	}
+	imageNames := make(map[string]struct{}, len(imageFiles))
+	for _, img := range imageFiles {
+		imageNames[img.Filename] = struct{}{}
+	}
+	for i, item := range ds.Items {
+		if item.ImageRef == "" {
+			continue
+		}
+		if _, ok := imageNames[item.ImageRef]; !ok {
+			return fmt.Errorf("dataset.items[%d].image_ref must match an uploaded filename", i)
+		}
+	}
+	return nil
 }


thinking
**Adding imports and tests**

I'm updating handler_test.go by adding necessary imports and a helper function, then creating tests to cover the new functionality before applying the patch.
file update
M /Users/yani/Noema/backend/internal/evaluate/handler_test.go
@@ -3,4 +3,7 @@
 import (
+	"bytes"
 	"encoding/json"
+	"fmt"
 	"mime/multipart"
+	"net/textproto"
 	"sort"
@@ -9,2 +12,43 @@
 
+type formFile struct {
+	field       string
+	filename    string
+	contentType string
+	content     []byte
+}
+
+func buildMultipartForm(t *testing.T, files []formFile) *multipart.Form {
+	t.Helper()
+
+	var buf bytes.Buffer
+	writer := multipart.NewWriter(&buf)
+	for _, f := range files {
+		header := make(textproto.MIMEHeader)
+		header.Set("Content-Disposition", fmt.Sprintf(`form-data; name="%s"; filename="%s"`, f.field, f.filename))
+		if f.contentType != "" {
+			header.Set("Content-Type", f.contentType)
+		}
+		part, err := writer.CreatePart(header)
+		if err != nil {
+			t.Fatalf("create part: %v", err)
+		}
+		if _, err := part.Write(f.content); err != nil {
+			t.Fatalf("write part: %v", err)
+		}
+	}
+	if err := writer.Close(); err != nil {
+		t.Fatalf("close writer: %v", err)
+	}
+
+	reader := multipart.NewReader(&buf, writer.Boundary())
+	form, err := reader.ReadForm(10 << 20)
+	if err != nil {
+		t.Fatalf("read form: %v", err)
+	}
+	t.Cleanup(func() {
+		form.RemoveAll()
+	})
+	return form
+}
+
 func TestParseEvalOutputOptional_DefaultsToStub(t *testing.T) {
@@ -145 +189,25 @@
 }
+
+func TestValidateDatasetJSON_ImageRefRequiresImages(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+	})
+	datasetFile := form.File["dataset"][0]
+	if err := validateDatasetJSON(datasetFile, nil); err == nil {
+		t.Fatalf("expected error for image_ref without images")
+	}
+}
+
+func TestValidateDatasetJSON_ImageRefMatchesUpload(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+		{field: "images", filename: "img1.png", contentType: "image/png", content: []byte("png")},
+	})
+	datasetFile := form.File["dataset"][0]
+	imageFiles := form.File["images"]
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		t.Fatalf("unexpected error: %v", err)
+	}
+}
apply_patch(auto_approved=true) exited 0 in 19ms:
Success. Updated the following files:
M /Users/yani/Noema/backend/internal/evaluate/handler_test.go
file update:
diff --git a/backend/internal/evaluate/handler_test.go b/backend/internal/evaluate/handler_test.go
index c472642af795537c60f82553d609bc48acaf51f3..183c064a31a280c8ca8dba5b4c55420b2f8d445a
--- a/backend/internal/evaluate/handler_test.go
+++ b/backend/internal/evaluate/handler_test.go
@@ -1,12 +1,56 @@
 package evaluate
 
 import (
+	"bytes"
 	"encoding/json"
+	"fmt"
 	"mime/multipart"
+	"net/textproto"
 	"sort"
 	"testing"
 )
 
+type formFile struct {
+	field       string
+	filename    string
+	contentType string
+	content     []byte
+}
+
+func buildMultipartForm(t *testing.T, files []formFile) *multipart.Form {
+	t.Helper()
+
+	var buf bytes.Buffer
+	writer := multipart.NewWriter(&buf)
+	for _, f := range files {
+		header := make(textproto.MIMEHeader)
+		header.Set("Content-Disposition", fmt.Sprintf(`form-data; name="%s"; filename="%s"`, f.field, f.filename))
+		if f.contentType != "" {
+			header.Set("Content-Type", f.contentType)
+		}
+		part, err := writer.CreatePart(header)
+		if err != nil {
+			t.Fatalf("create part: %v", err)
+		}
+		if _, err := part.Write(f.content); err != nil {
+			t.Fatalf("write part: %v", err)
+		}
+	}
+	if err := writer.Close(); err != nil {
+		t.Fatalf("close writer: %v", err)
+	}
+
+	reader := multipart.NewReader(&buf, writer.Boundary())
+	form, err := reader.ReadForm(10 << 20)
+	if err != nil {
+		t.Fatalf("read form: %v", err)
+	}
+	t.Cleanup(func() {
+		form.RemoveAll()
+	})
+	return form
+}
+
 func TestParseEvalOutputOptional_DefaultsToStub(t *testing.T) {
 	spec := Spec{
 		SchemaVersion: 1,
@@ -143,3 +187,27 @@
 		t.Fatalf("expected overall pass false due to pii threshold")
 	}
 }
+
+func TestValidateDatasetJSON_ImageRefRequiresImages(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+	})
+	datasetFile := form.File["dataset"][0]
+	if err := validateDatasetJSON(datasetFile, nil); err == nil {
+		t.Fatalf("expected error for image_ref without images")
+	}
+}
+
+func TestValidateDatasetJSON_ImageRefMatchesUpload(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+		{field: "images", filename: "img1.png", contentType: "image/png", content: []byte("png")},
+	})
+	datasetFile := form.File["dataset"][0]
+	imageFiles := form.File["images"]
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		t.Fatalf("unexpected error: %v", err)
+	}
+}
diff --git a/backend/internal/evaluate/parse.go b/backend/internal/evaluate/parse.go
index 52f3936303d07fdb5fb866257779af77cb860f81..5fc2e874e76c17e562acdc5bd1a08ade0d900cf6
--- a/backend/internal/evaluate/parse.go
+++ b/backend/internal/evaluate/parse.go
@@ -46,10 +46,6 @@
 	if datasetFile.Size > config.MaxDatasetBytes {
 		return nil, nil, fmt.Errorf("dataset exceeds 50MB limit")
 	}
-	if err := validateDatasetJSON(datasetFile); err != nil {
-		return nil, nil, err
-	}
-
 	imageFiles := form.File["images"]
 	if len(imageFiles) > config.MaxImages {
 		return nil, nil, fmt.Errorf("maximum 10 images allowed")
@@ -59,10 +55,36 @@
 			return nil, nil, fmt.Errorf("each image must be at most 5MB")
 		}
 	}
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		return nil, nil, err
+	}
 	return datasetFile, imageFiles, nil
 }
 
-func validateDatasetJSON(fh *multipart.FileHeader) error {
-	_, _, err := readDatasetFile(fh)
-	return err
+func validateDatasetJSON(fh *multipart.FileHeader, imageFiles []*multipart.FileHeader) error {
+	_, ds, err := readDatasetFile(fh)
+	if err != nil {
+		return err
+	}
+	if len(imageFiles) == 0 {
+		for i, item := range ds.Items {
+			if item.ImageRef != "" {
+				return fmt.Errorf("dataset.items[%d].image_ref provided but no images uploaded", i)
+			}
+		}
+		return nil
+	}
+	imageNames := make(map[string]struct{}, len(imageFiles))
+	for _, img := range imageFiles {
+		imageNames[img.Filename] = struct{}{}
+	}
+	for i, item := range ds.Items {
+		if item.ImageRef == "" {
+			continue
+		}
+		if _, ok := imageNames[item.ImageRef]; !ok {
+			return fmt.Errorf("dataset.items[%d].image_ref must match an uploaded filename", i)
+		}
+	}
+	return nil
 }

file update:
diff --git a/backend/internal/evaluate/handler_test.go b/backend/internal/evaluate/handler_test.go
index c472642af795537c60f82553d609bc48acaf51f3..183c064a31a280c8ca8dba5b4c55420b2f8d445a
--- a/backend/internal/evaluate/handler_test.go
+++ b/backend/internal/evaluate/handler_test.go
@@ -1,12 +1,56 @@
 package evaluate
 
 import (
+	"bytes"
 	"encoding/json"
+	"fmt"
 	"mime/multipart"
+	"net/textproto"
 	"sort"
 	"testing"
 )
 
+type formFile struct {
+	field       string
+	filename    string
+	contentType string
+	content     []byte
+}
+
+func buildMultipartForm(t *testing.T, files []formFile) *multipart.Form {
+	t.Helper()
+
+	var buf bytes.Buffer
+	writer := multipart.NewWriter(&buf)
+	for _, f := range files {
+		header := make(textproto.MIMEHeader)
+		header.Set("Content-Disposition", fmt.Sprintf(`form-data; name="%s"; filename="%s"`, f.field, f.filename))
+		if f.contentType != "" {
+			header.Set("Content-Type", f.contentType)
+		}
+		part, err := writer.CreatePart(header)
+		if err != nil {
+			t.Fatalf("create part: %v", err)
+		}
+		if _, err := part.Write(f.content); err != nil {
+			t.Fatalf("write part: %v", err)
+		}
+	}
+	if err := writer.Close(); err != nil {
+		t.Fatalf("close writer: %v", err)
+	}
+
+	reader := multipart.NewReader(&buf, writer.Boundary())
+	form, err := reader.ReadForm(10 << 20)
+	if err != nil {
+		t.Fatalf("read form: %v", err)
+	}
+	t.Cleanup(func() {
+		form.RemoveAll()
+	})
+	return form
+}
+
 func TestParseEvalOutputOptional_DefaultsToStub(t *testing.T) {
 	spec := Spec{
 		SchemaVersion: 1,
@@ -143,3 +187,27 @@
 		t.Fatalf("expected overall pass false due to pii threshold")
 	}
 }
+
+func TestValidateDatasetJSON_ImageRefRequiresImages(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+	})
+	datasetFile := form.File["dataset"][0]
+	if err := validateDatasetJSON(datasetFile, nil); err == nil {
+		t.Fatalf("expected error for image_ref without images")
+	}
+}
+
+func TestValidateDatasetJSON_ImageRefMatchesUpload(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+		{field: "images", filename: "img1.png", contentType: "image/png", content: []byte("png")},
+	})
+	datasetFile := form.File["dataset"][0]
+	imageFiles := form.File["images"]
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		t.Fatalf("unexpected error: %v", err)
+	}
+}
diff --git a/backend/internal/evaluate/parse.go b/backend/internal/evaluate/parse.go
index 52f3936303d07fdb5fb866257779af77cb860f81..5fc2e874e76c17e562acdc5bd1a08ade0d900cf6
--- a/backend/internal/evaluate/parse.go
+++ b/backend/internal/evaluate/parse.go
@@ -46,10 +46,6 @@
 	if datasetFile.Size > config.MaxDatasetBytes {
 		return nil, nil, fmt.Errorf("dataset exceeds 50MB limit")
 	}
-	if err := validateDatasetJSON(datasetFile); err != nil {
-		return nil, nil, err
-	}
-
 	imageFiles := form.File["images"]
 	if len(imageFiles) > config.MaxImages {
 		return nil, nil, fmt.Errorf("maximum 10 images allowed")
@@ -59,10 +55,36 @@
 			return nil, nil, fmt.Errorf("each image must be at most 5MB")
 		}
 	}
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		return nil, nil, err
+	}
 	return datasetFile, imageFiles, nil
 }
 
-func validateDatasetJSON(fh *multipart.FileHeader) error {
-	_, _, err := readDatasetFile(fh)
-	return err
+func validateDatasetJSON(fh *multipart.FileHeader, imageFiles []*multipart.FileHeader) error {
+	_, ds, err := readDatasetFile(fh)
+	if err != nil {
+		return err
+	}
+	if len(imageFiles) == 0 {
+		for i, item := range ds.Items {
+			if item.ImageRef != "" {
+				return fmt.Errorf("dataset.items[%d].image_ref provided but no images uploaded", i)
+			}
+		}
+		return nil
+	}
+	imageNames := make(map[string]struct{}, len(imageFiles))
+	for _, img := range imageFiles {
+		imageNames[img.Filename] = struct{}{}
+	}
+	for i, item := range ds.Items {
+		if item.ImageRef == "" {
+			continue
+		}
+		if _, ok := imageNames[item.ImageRef]; !ok {
+			return fmt.Errorf("dataset.items[%d].image_ref must match an uploaded filename", i)
+		}
+	}
+	return nil
 }


thinking
**Running full test suite**
exec
/bin/zsh -lc 'cd /Users/yani/Noema/backend && go test ./...' in /Users/yani/Noema/backendfile update:
diff --git a/backend/internal/evaluate/handler_test.go b/backend/internal/evaluate/handler_test.go
index c472642af795537c60f82553d609bc48acaf51f3..183c064a31a280c8ca8dba5b4c55420b2f8d445a
--- a/backend/internal/evaluate/handler_test.go
+++ b/backend/internal/evaluate/handler_test.go
@@ -1,12 +1,56 @@
 package evaluate
 
 import (
+	"bytes"
 	"encoding/json"
+	"fmt"
 	"mime/multipart"
+	"net/textproto"
 	"sort"
 	"testing"
 )
 
+type formFile struct {
+	field       string
+	filename    string
+	contentType string
+	content     []byte
+}
+
+func buildMultipartForm(t *testing.T, files []formFile) *multipart.Form {
+	t.Helper()
+
+	var buf bytes.Buffer
+	writer := multipart.NewWriter(&buf)
+	for _, f := range files {
+		header := make(textproto.MIMEHeader)
+		header.Set("Content-Disposition", fmt.Sprintf(`form-data; name="%s"; filename="%s"`, f.field, f.filename))
+		if f.contentType != "" {
+			header.Set("Content-Type", f.contentType)
+		}
+		part, err := writer.CreatePart(header)
+		if err != nil {
+			t.Fatalf("create part: %v", err)
+		}
+		if _, err := part.Write(f.content); err != nil {
+			t.Fatalf("write part: %v", err)
+		}
+	}
+	if err := writer.Close(); err != nil {
+		t.Fatalf("close writer: %v", err)
+	}
+
+	reader := multipart.NewReader(&buf, writer.Boundary())
+	form, err := reader.ReadForm(10 << 20)
+	if err != nil {
+		t.Fatalf("read form: %v", err)
+	}
+	t.Cleanup(func() {
+		form.RemoveAll()
+	})
+	return form
+}
+
 func TestParseEvalOutputOptional_DefaultsToStub(t *testing.T) {
 	spec := Spec{
 		SchemaVersion: 1,
@@ -143,3 +187,27 @@
 		t.Fatalf("expected overall pass false due to pii threshold")
 	}
 }
+
+func TestValidateDatasetJSON_ImageRefRequiresImages(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+	})
+	datasetFile := form.File["dataset"][0]
+	if err := validateDatasetJSON(datasetFile, nil); err == nil {
+		t.Fatalf("expected error for image_ref without images")
+	}
+}
+
+func TestValidateDatasetJSON_ImageRefMatchesUpload(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+		{field: "images", filename: "img1.png", contentType: "image/png", content: []byte("png")},
+	})
+	datasetFile := form.File["dataset"][0]
+	imageFiles := form.File["images"]
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		t.Fatalf("unexpected error: %v", err)
+	}
+}
diff --git a/backend/internal/evaluate/parse.go b/backend/internal/evaluate/parse.go
index 52f3936303d07fdb5fb866257779af77cb860f81..5fc2e874e76c17e562acdc5bd1a08ade0d900cf6
--- a/backend/internal/evaluate/parse.go
+++ b/backend/internal/evaluate/parse.go
@@ -46,10 +46,6 @@
 	if datasetFile.Size > config.MaxDatasetBytes {
 		return nil, nil, fmt.Errorf("dataset exceeds 50MB limit")
 	}
-	if err := validateDatasetJSON(datasetFile); err != nil {
-		return nil, nil, err
-	}
-
 	imageFiles := form.File["images"]
 	if len(imageFiles) > config.MaxImages {
 		return nil, nil, fmt.Errorf("maximum 10 images allowed")
@@ -59,10 +55,36 @@
 			return nil, nil, fmt.Errorf("each image must be at most 5MB")
 		}
 	}
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		return nil, nil, err
+	}
 	return datasetFile, imageFiles, nil
 }
 
-func validateDatasetJSON(fh *multipart.FileHeader) error {
-	_, _, err := readDatasetFile(fh)
-	return err
+func validateDatasetJSON(fh *multipart.FileHeader, imageFiles []*multipart.FileHeader) error {
+	_, ds, err := readDatasetFile(fh)
+	if err != nil {
+		return err
+	}
+	if len(imageFiles) == 0 {
+		for i, item := range ds.Items {
+			if item.ImageRef != "" {
+				return fmt.Errorf("dataset.items[%d].image_ref provided but no images uploaded", i)
+			}
+		}
+		return nil
+	}
+	imageNames := make(map[string]struct{}, len(imageFiles))
+	for _, img := range imageFiles {
+		imageNames[img.Filename] = struct{}{}
+	}
+	for i, item := range ds.Items {
+		if item.ImageRef == "" {
+			continue
+		}
+		if _, ok := imageNames[item.ImageRef]; !ok {
+			return fmt.Errorf("dataset.items[%d].image_ref must match an uploaded filename", i)
+		}
+	}
+	return nil
 }

 succeeded in 1.66s:
?   	noema/cmd/server	[no test files]
?   	noema/internal/auth	[no test files]
?   	noema/internal/config	[no test files]
?   	noema/internal/crypto	[no test files]
ok  	noema/internal/evaluate	0.017s
?   	noema/internal/gemini	[no test files]
?   	noema/internal/session	[no test files]
?   	noema/internal/verify	[no test files]
?   	noema/internal/web	[no test files]
ok  	noema/internal/zk	(cached)
file update:
diff --git a/backend/internal/evaluate/handler_test.go b/backend/internal/evaluate/handler_test.go
index c472642af795537c60f82553d609bc48acaf51f3..183c064a31a280c8ca8dba5b4c55420b2f8d445a
--- a/backend/internal/evaluate/handler_test.go
+++ b/backend/internal/evaluate/handler_test.go
@@ -1,12 +1,56 @@
 package evaluate
 
 import (
+	"bytes"
 	"encoding/json"
+	"fmt"
 	"mime/multipart"
+	"net/textproto"
 	"sort"
 	"testing"
 )
 
+type formFile struct {
+	field       string
+	filename    string
+	contentType string
+	content     []byte
+}
+
+func buildMultipartForm(t *testing.T, files []formFile) *multipart.Form {
+	t.Helper()
+
+	var buf bytes.Buffer
+	writer := multipart.NewWriter(&buf)
+	for _, f := range files {
+		header := make(textproto.MIMEHeader)
+		header.Set("Content-Disposition", fmt.Sprintf(`form-data; name="%s"; filename="%s"`, f.field, f.filename))
+		if f.contentType != "" {
+			header.Set("Content-Type", f.contentType)
+		}
+		part, err := writer.CreatePart(header)
+		if err != nil {
+			t.Fatalf("create part: %v", err)
+		}
+		if _, err := part.Write(f.content); err != nil {
+			t.Fatalf("write part: %v", err)
+		}
+	}
+	if err := writer.Close(); err != nil {
+		t.Fatalf("close writer: %v", err)
+	}
+
+	reader := multipart.NewReader(&buf, writer.Boundary())
+	form, err := reader.ReadForm(10 << 20)
+	if err != nil {
+		t.Fatalf("read form: %v", err)
+	}
+	t.Cleanup(func() {
+		form.RemoveAll()
+	})
+	return form
+}
+
 func TestParseEvalOutputOptional_DefaultsToStub(t *testing.T) {
 	spec := Spec{
 		SchemaVersion: 1,
@@ -143,3 +187,27 @@
 		t.Fatalf("expected overall pass false due to pii threshold")
 	}
 }
+
+func TestValidateDatasetJSON_ImageRefRequiresImages(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+	})
+	datasetFile := form.File["dataset"][0]
+	if err := validateDatasetJSON(datasetFile, nil); err == nil {
+		t.Fatalf("expected error for image_ref without images")
+	}
+}
+
+func TestValidateDatasetJSON_ImageRefMatchesUpload(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+		{field: "images", filename: "img1.png", contentType: "image/png", content: []byte("png")},
+	})
+	datasetFile := form.File["dataset"][0]
+	imageFiles := form.File["images"]
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		t.Fatalf("unexpected error: %v", err)
+	}
+}
diff --git a/backend/internal/evaluate/parse.go b/backend/internal/evaluate/parse.go
index 52f3936303d07fdb5fb866257779af77cb860f81..5fc2e874e76c17e562acdc5bd1a08ade0d900cf6
--- a/backend/internal/evaluate/parse.go
+++ b/backend/internal/evaluate/parse.go
@@ -46,10 +46,6 @@
 	if datasetFile.Size > config.MaxDatasetBytes {
 		return nil, nil, fmt.Errorf("dataset exceeds 50MB limit")
 	}
-	if err := validateDatasetJSON(datasetFile); err != nil {
-		return nil, nil, err
-	}
-
 	imageFiles := form.File["images"]
 	if len(imageFiles) > config.MaxImages {
 		return nil, nil, fmt.Errorf("maximum 10 images allowed")
@@ -59,10 +55,36 @@
 			return nil, nil, fmt.Errorf("each image must be at most 5MB")
 		}
 	}
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		return nil, nil, err
+	}
 	return datasetFile, imageFiles, nil
 }
 
-func validateDatasetJSON(fh *multipart.FileHeader) error {
-	_, _, err := readDatasetFile(fh)
-	return err
+func validateDatasetJSON(fh *multipart.FileHeader, imageFiles []*multipart.FileHeader) error {
+	_, ds, err := readDatasetFile(fh)
+	if err != nil {
+		return err
+	}
+	if len(imageFiles) == 0 {
+		for i, item := range ds.Items {
+			if item.ImageRef != "" {
+				return fmt.Errorf("dataset.items[%d].image_ref provided but no images uploaded", i)
+			}
+		}
+		return nil
+	}
+	imageNames := make(map[string]struct{}, len(imageFiles))
+	for _, img := range imageFiles {
+		imageNames[img.Filename] = struct{}{}
+	}
+	for i, item := range ds.Items {
+		if item.ImageRef == "" {
+			continue
+		}
+		if _, ok := imageNames[item.ImageRef]; !ok {
+			return fmt.Errorf("dataset.items[%d].image_ref must match an uploaded filename", i)
+		}
+	}
+	return nil
 }

codex
What I changed
- Added dataset image reference validation so `items[].image_ref` must match an uploaded image (and error if images are missing).
- Added tests covering image_ref validation with and without uploads.

Tests run
- `go test ./...`

Files touched
- `internal/evaluate/parse.go`
- `internal/evaluate/handler_test.go`
file update:
diff --git a/backend/internal/evaluate/handler_test.go b/backend/internal/evaluate/handler_test.go
index c472642af795537c60f82553d609bc48acaf51f3..183c064a31a280c8ca8dba5b4c55420b2f8d445a
--- a/backend/internal/evaluate/handler_test.go
+++ b/backend/internal/evaluate/handler_test.go
@@ -1,12 +1,56 @@
 package evaluate
 
 import (
+	"bytes"
 	"encoding/json"
+	"fmt"
 	"mime/multipart"
+	"net/textproto"
 	"sort"
 	"testing"
 )
 
+type formFile struct {
+	field       string
+	filename    string
+	contentType string
+	content     []byte
+}
+
+func buildMultipartForm(t *testing.T, files []formFile) *multipart.Form {
+	t.Helper()
+
+	var buf bytes.Buffer
+	writer := multipart.NewWriter(&buf)
+	for _, f := range files {
+		header := make(textproto.MIMEHeader)
+		header.Set("Content-Disposition", fmt.Sprintf(`form-data; name="%s"; filename="%s"`, f.field, f.filename))
+		if f.contentType != "" {
+			header.Set("Content-Type", f.contentType)
+		}
+		part, err := writer.CreatePart(header)
+		if err != nil {
+			t.Fatalf("create part: %v", err)
+		}
+		if _, err := part.Write(f.content); err != nil {
+			t.Fatalf("write part: %v", err)
+		}
+	}
+	if err := writer.Close(); err != nil {
+		t.Fatalf("close writer: %v", err)
+	}
+
+	reader := multipart.NewReader(&buf, writer.Boundary())
+	form, err := reader.ReadForm(10 << 20)
+	if err != nil {
+		t.Fatalf("read form: %v", err)
+	}
+	t.Cleanup(func() {
+		form.RemoveAll()
+	})
+	return form
+}
+
 func TestParseEvalOutputOptional_DefaultsToStub(t *testing.T) {
 	spec := Spec{
 		SchemaVersion: 1,
@@ -143,3 +187,27 @@
 		t.Fatalf("expected overall pass false due to pii threshold")
 	}
 }
+
+func TestValidateDatasetJSON_ImageRefRequiresImages(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+	})
+	datasetFile := form.File["dataset"][0]
+	if err := validateDatasetJSON(datasetFile, nil); err == nil {
+		t.Fatalf("expected error for image_ref without images")
+	}
+}
+
+func TestValidateDatasetJSON_ImageRefMatchesUpload(t *testing.T) {
+	dataset := `{"items":[{"id":"1","text":"hello","image_ref":"img1.png"}]}`
+	form := buildMultipartForm(t, []formFile{
+		{field: "dataset", filename: "dataset.json", contentType: "application/json", content: []byte(dataset)},
+		{field: "images", filename: "img1.png", contentType: "image/png", content: []byte("png")},
+	})
+	datasetFile := form.File["dataset"][0]
+	imageFiles := form.File["images"]
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		t.Fatalf("unexpected error: %v", err)
+	}
+}
diff --git a/backend/internal/evaluate/parse.go b/backend/internal/evaluate/parse.go
index 52f3936303d07fdb5fb866257779af77cb860f81..5fc2e874e76c17e562acdc5bd1a08ade0d900cf6
--- a/backend/internal/evaluate/parse.go
+++ b/backend/internal/evaluate/parse.go
@@ -46,10 +46,6 @@
 	if datasetFile.Size > config.MaxDatasetBytes {
 		return nil, nil, fmt.Errorf("dataset exceeds 50MB limit")
 	}
-	if err := validateDatasetJSON(datasetFile); err != nil {
-		return nil, nil, err
-	}
-
 	imageFiles := form.File["images"]
 	if len(imageFiles) > config.MaxImages {
 		return nil, nil, fmt.Errorf("maximum 10 images allowed")
@@ -59,10 +55,36 @@
 			return nil, nil, fmt.Errorf("each image must be at most 5MB")
 		}
 	}
+	if err := validateDatasetJSON(datasetFile, imageFiles); err != nil {
+		return nil, nil, err
+	}
 	return datasetFile, imageFiles, nil
 }
 
-func validateDatasetJSON(fh *multipart.FileHeader) error {
-	_, _, err := readDatasetFile(fh)
-	return err
+func validateDatasetJSON(fh *multipart.FileHeader, imageFiles []*multipart.FileHeader) error {
+	_, ds, err := readDatasetFile(fh)
+	if err != nil {
+		return err
+	}
+	if len(imageFiles) == 0 {
+		for i, item := range ds.Items {
+			if item.ImageRef != "" {
+				return fmt.Errorf("dataset.items[%d].image_ref provided but no images uploaded", i)
+			}
+		}
+		return nil
+	}
+	imageNames := make(map[string]struct{}, len(imageFiles))
+	for _, img := range imageFiles {
+		imageNames[img.Filename] = struct{}{}
+	}
+	for i, item := range ds.Items {
+		if item.ImageRef == "" {
+			continue
+		}
+		if _, ok := imageNames[item.ImageRef]; !ok {
+			return fmt.Errorf("dataset.items[%d].image_ref must match an uploaded filename", i)
+		}
+	}
+	return nil
 }

tokens used
37,203
What I changed
- Added dataset image reference validation so `items[].image_ref` must match an uploaded image (and error if images are missing).
- Added tests covering image_ref validation with and without uploads.

Tests run
- `go test ./...`

Files touched
- `internal/evaluate/parse.go`
- `internal/evaluate/handler_test.go`
